{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import re \n",
    "import string\n",
    "import pickle\n",
    "import numpy as np \n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Force CPU computation\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files\n",
    "with open(\"../data/task2/train.en\", \"r\") as f:\n",
    "    train_en = f.read().split(\"\\n\")\n",
    "    \n",
    "with open(\"../data/task2/train.hi\", \"r\") as f:\n",
    "    train_hi = f.read().split(\"\\n\")\n",
    "    \n",
    "with open(\"../data/task2/dev.en\", \"r\") as f:\n",
    "    dev_en = f.read().split(\"\\n\")\n",
    "    \n",
    "with open(\"../data/task2/dev.hi\", \"r\") as f:\n",
    "    dev_hi = f.read().split(\"\\n\")\n",
    "    \n",
    "with open(\"../saved_data/machine_translation/lstm/en_tokenizer.pkl\", \"rb\") as f:\n",
    "    en_tokenizer = pickle.load(f)\n",
    "    \n",
    "with open(\"../saved_data/machine_translation/lstm/hi_tokenizer.pkl\", \"rb\") as f:\n",
    "    hi_tokenizer = pickle.load(f)\n",
    "    \n",
    "puncts = string.punctuation + train_hi[3][-1]\n",
    "\n",
    "\n",
    "def preprocess_line(line):\n",
    "    line = line.translate(str.maketrans(\"\", \"\", puncts))\n",
    "    line = re.sub(\"\\u200b\", \" \", line)\n",
    "    line = re.sub(\"\\u200d\", \" \", line)\n",
    "    line = re.sub(\"\\d+\", \" \", line)\n",
    "    line = line.lower()\n",
    "    line = \" \".join(line.split())\n",
    "    return line\n",
    "\n",
    "train_en = [preprocess_line(line) for line in train_en]\n",
    "train_hi = [preprocess_line(line) for line in train_hi]\n",
    "dev_en = [preprocess_line(line) for line in dev_en]\n",
    "dev_hi = [preprocess_line(line) for line in dev_hi]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(enc_path, dec_path):\n",
    "    encoder_model = load_model(enc_path)\n",
    "    decoder_model = load_model(dec_path)\n",
    "    return encoder_model, decoder_model\n",
    "\n",
    "\n",
    "def translate(input_sentence):\n",
    "    line = preprocess_line(input_sentence)\n",
    "    tokens = en_tokenizer.texts_to_sequences([line])\n",
    "    tokens = pad_sequences(tokens, maxlen=30, padding='post')\n",
    "    tokens = np.flip(tokens)\n",
    "    \n",
    "    init_states = encoder_model(tokens)\n",
    "    dec_in = tf.expand_dims([hi_tokenizer.word_index['startseq']], 1)\n",
    "    \n",
    "    words = []\n",
    "    \n",
    "    for t in range(29):\n",
    "        preds, init_states = decoder_model([dec_in, init_states])\n",
    "        pred_idx = np.argmax(preds, -1)[0]\n",
    "        word = hi_tokenizer.index_word.get(pred_idx)\n",
    "        \n",
    "        if word is None or word == \"endseq\":\n",
    "            break\n",
    "            \n",
    "        words.append(word)\n",
    "        dec_in = tf.expand_dims([pred_idx], 1)\n",
    "        \n",
    "    return \" \".join(words)\n",
    "\n",
    "\n",
    "def evaluate_model(input_sentences, output_sentences):\n",
    "    actual, predicted = [], []\n",
    "    for in_line, out_line in tqdm(zip(input_sentences, output_sentences), \n",
    "                                  total=len(input_sentences)):\n",
    "        hypothesis = translate(in_line)\n",
    "        references = out_line\n",
    "        actual.append([references.split()])\n",
    "        predicted.append(hypothesis.split())\n",
    "    \n",
    "    print(\"BLEU-1: {:.3f}\".format(corpus_bleu(actual, predicted, weights=(1., 0, 0, 0))))\n",
    "    print(\"BLEU-2: {:.3f}\".format(corpus_bleu(actual, predicted, weights=(.5, .5, 0, 0))))\n",
    "    print(\"BLEU-3: {:.3f}\".format(corpus_bleu(actual, predicted, weights=(.3, .3, .3, 0))))\n",
    "    print(\"BLEU-4: {:.3f}\".format(corpus_bleu(actual, predicted, weights=(.25, .25, .25, .25))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c031ec35fef44178ada5d739df463fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BLEU-1: 0.371\n",
      "BLEU-2: 0.268\n",
      "BLEU-3: 0.236\n",
      "BLEU-4: 0.159\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6fa5bd9003a4d838f83850f776aa1f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=501.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BLEU-1: 0.207\n",
      "BLEU-2: 0.085\n",
      "BLEU-3: 0.053\n",
      "BLEU-4: 0.017\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "encoder_model, decoder_model = load_models(\n",
    "    enc_path = \"../saved_data/machine_translation/lstm/models/encoder_30\",\n",
    "    dec_path = \"../saved_data/machine_translation/lstm/models/decoder_30\"\n",
    ")\n",
    "\n",
    "# Train data evaluation\n",
    "evaluate_model(train_en[:5000], train_hi[:5000])\n",
    "\n",
    "# Development data evaluation\n",
    "evaluate_model(dev_en, dev_hi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ENGLISH]: What are we doing here?\n",
      "\n",
      "[HINDI]: यहाँ क्या कर रहे हैं\n"
     ]
    }
   ],
   "source": [
    "input_sentence = \"What are we doing here?\"\n",
    "\n",
    "print(\"[ENGLISH]: {}\".format(input_sentence))\n",
    "print(\"\\n[HINDI]: {}\".format(translate(input_sentence)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
